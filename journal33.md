2019/7/13  
随机森林
===========  
1、`随机森林`构建多个决策树，并将它们合并在一起，得到更准确、更稳定的预测。随机森林是用来分类和回归的监督集成学习模型。  

2、`集成学习模型`聚合了多个机器学习模型，从而提高了整体性能。这背后的逻辑是，使用的每一个模型在单独使用时都是弱的，但在集成中放在一起时则是强的。在随机森林的情况下，使用大量的决策树作为弱因子，并对它们的输出进行聚合，结果表示强集合。  

3、`随机森林算法`有两个步骤，一个是随机森林的生成，另一个是随机预测在第一步中创建森林分类器。  

4、`随机森林算法和决策树算法的不同之处`在于，在随机森林中，查找根节点和分割特征节点的过程将随机运行。在随机森林算法中的决策树，`每棵树的生长方式`如下：1.如果训练集中的病例数为N，有放回的随机抽取n个，这个样本将是生成决策树的训练集。2.（特征的随机选取）对于每个样本，如果有M个输入变量（或者特征），指定一个常数m，然后随机的从M个特征中选取m个特征子集，然后将m个特征中最优的分裂特征用来分裂节点。

5、随机森林的预测分为以下三步：1.使用每一个随即创建的决策树的规则来预测测试特征的结果（目标）。2.计算每个预测目标的票数。3.获得票数最高的预测目标视为随机森林算法的最终预测。
